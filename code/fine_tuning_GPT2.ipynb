{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwk6OoI2Ep7Z"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9PhAQicEyQd"
      },
      "outputs": [],
      "source": [
        "!pip install -U PyPDF2\n",
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ItYpaZD9EH7J",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "import os\n",
        "import docx\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### proxy service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
        "output = result.stdout\n",
        "for line in output.splitlines():\n",
        "    if '=' in line:\n",
        "        var, value = line.split('=', 1)\n",
        "        os.environ[var] = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ly_QfYPDHlie",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "# Functions to read different file types\n",
        "def read_pdf(file_path):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def read_word(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    text = \"\"\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text += paragraph.text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def read_txt(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def read_documents_from_directory(directory):\n",
        "    combined_text = []\n",
        "    for i, filename in enumerate(os.listdir(directory)):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            new_text = read_pdf(file_path)\n",
        "        elif filename.endswith(\".docx\"):\n",
        "            new_text = read_word(file_path)\n",
        "        elif filename.endswith(\".txt\"):\n",
        "            new_text = read_txt(file_path)\n",
        "        # new_text = re.sub(r'\\n+', '\\n', new_text).strip()\n",
        "        combined_text.append(new_text)\n",
        "        if i == 9:\n",
        "            break\n",
        "    return combined_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oobynnecHx87",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/autodl-tmp/Fine-Tuned-GPT-2-with-articles-ground-truth/.conda/lib/python3.11/site-packages/PyPDF2/_cmap.py:151: PdfReadWarning: Advanced encoding [] not implemented yet\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load documents from the directory\n",
        "data_path = '/root/autodl-tmp/Fine-Tuned-GPT-2-with-articles-ground-truth/data'\n",
        "all_text = read_documents_from_directory(os.path.join(data_path, \"ori_papers\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-ZaBPMO-GZQP",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "# Save the training and validation data as text files\n",
        "train_vs_test = [7, 3]\n",
        "train_id = int(len(all_text)/10*7)\n",
        "\n",
        "train_text = \"\".join(all_text[:train_id])\n",
        "test_text = \"\".join(all_text[train_id:])\n",
        "\n",
        "if os.path.exists(os.path.join(data_path, \"dataset\")):\n",
        "   shutil.rmtree(os.path.join(data_path, \"dataset\"))\n",
        "os.makedirs(os.path.join(data_path, \"dataset\"))\n",
        "\n",
        "with open(os.path.join(data_path, \"dataset/train.txt\"), \"w\") as f:\n",
        "   f.write(train_text)\n",
        "with open(os.path.join(data_path, \"dataset/test.txt\"), \"w\") as f:\n",
        "   f.write(test_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9MFaNgaDEVKP",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Wk_14dI9EVdD",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "def load_dataset(file_path, tokenizer, block_size = 128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer = tokenizer,\n",
        "        file_path = file_path,\n",
        "        block_size = block_size,\n",
        "    )\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QJcoT-aNFcKp",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "def load_data_collator(tokenizer, mlm = False):\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, \n",
        "        mlm=mlm,\n",
        "    )\n",
        "    return data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "def train(train_file_path, model_name, \n",
        "          output_dir, \n",
        "          overwrite_output_dir, \n",
        "          per_device_train_batch_size, \n",
        "          num_train_epochs, \n",
        "          save_steps,\n",
        "          logging_steps=500):\n",
        "    \n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "    os.makedirs(os.path.join(output_dir, \"tokenizer\"))\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    train_dataset = load_dataset(train_file_path, tokenizer)\n",
        "    data_collator = load_data_collator(tokenizer)\n",
        "    tokenizer.save_pretrained(os.path.join(output_dir, 'tokenizer'))\n",
        "\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "    model.save_pretrained(output_dir)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            overwrite_output_dir=overwrite_output_dir,\n",
        "            per_device_train_batch_size=per_device_train_batch_size,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            save_steps=save_steps,\n",
        "            logging_steps=logging_steps\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            data_collator=data_collator,\n",
        "            train_dataset=train_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model(os.path.join(output_dir, \"final\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9mXiWKHbFr2f",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "train_file_path = os.path.join(data_path, \"dataset/train.txt\")\n",
        "model_name = 'gpt2'\n",
        "output_dir = '/root/autodl-tmp/Fine-Tuned-GPT-2-with-articles-ground-truth/results'\n",
        "overwrite_output_dir = False\n",
        "per_device_train_batch_size = 8\n",
        "num_train_epochs = 50.0\n",
        "save_steps = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "WMdaTo7KF9uo",
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/autodl-tmp/Fine-Tuned-GPT-2-with-articles-ground-truth/.conda/lib/python3.11/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "/root/autodl-tmp/Fine-Tuned-GPT-2-with-articles-ground-truth/.conda/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7900' max='7900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7900/7900 06:02, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.538700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.903200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.540600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.255200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.025500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.840400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.696400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.584700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.506400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.443900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.355600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.326200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.306900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.292800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train\n",
        "train(\n",
        "    train_file_path=train_file_path,\n",
        "    model_name=model_name,\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=overwrite_output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_steps=save_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwGS1IMlGBMB"
      },
      "source": [
        "Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lelq_sN4Gy5M"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wOvrNQRAG2IP"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_tokenizer(model_path):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(os.path.join(model_path, \"tokenizer\"))\n",
        "    return tokenizer\n",
        "\n",
        "def generate_text(model_path, sequence, max_length):\n",
        "    \n",
        "    model = load_model(model_path)\n",
        "    tokenizer = load_tokenizer(model_path)\n",
        "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
        "    final_outputs = model.generate(\n",
        "        ids,\n",
        "        do_sample=True,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=model.config.eos_token_id,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvNx7gjeRieD"
      },
      "source": [
        "This model got trained on the entire text and took much longer to train, and yet it fails to give meaningful results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mTDTrpnG5Ut",
        "outputId": "e37387f1-beb6-4fa6-d5fd-ec2dfd775978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Q] What is the Monosaccharide?\n",
            "(a) Glucose\n",
            "(b) Sucrose\n",
            "(c) Fructose\n",
            "(d) Glucose\n",
            "Answer.  (b)\n",
            "480. Which of\n"
          ]
        }
      ],
      "source": [
        "model1_path = output_dir\n",
        "sequence1 = \"[Q] What is the Monosaccharide?\"\n",
        "max_len = 50\n",
        "generate_text(model1_path, sequence1, max_len) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNvBu4Jj2F8tAESALuZqmkV",
      "include_colab_link": true,
      "mount_file_id": "1WRB2uz0Mpfkw6AnDAxCOPwY_TT2tRizG",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
