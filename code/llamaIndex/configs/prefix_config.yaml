reader:
  "CustomDocumentReader":
    type: "CustomDocumentReader"
    config_file_path: "./code/llamaIndex/utils/config.json"
  "SimpleDirectoryReader":
    type: "SimpleDirectoryReader"
parser:
  "SimpleFileNodeParser":
    type: "SimpleFileNodeParser"
    retriever: "BaseRetriever"
  "SentenceSplitter":
    type: "SentenceSplitter"
    chunk_size: 512
    chunk_overlap: 20
    retriever: "BaseRetriever"
  "HierarchicalNodeParser":
    type: "HierarchicalNodeParser"
    chunk_size: [2048, 512, 128]
    retriever: "AutoMergingRetriever"
  "CustomHierarchicalNodeParser-ollama_vicuna_13b":
    type: "CustomHierarchicalNodeParser"
    retriever: "AutoMergingRetriever"
    llm: "vicuna:13b"
  "CustomHierarchicalNodeParser-hf_vicuna_13b":
    type: "CustomHierarchicalNodeParser"
    retriever: "AutoMergingRetriever"
    llm: "lmsys/vicuna-13b-v1.5"
  "ManualParser":
    type: "CustomHierarchicalNodeParser"
    retriever: "AutoMergingRetriever"
    llm: "lmsys/vicuna-13b-v1.5"
extractor:
  "vicuna-13b-QAExtractor-hf":
    name: "vicuna-13b-QAExtractor"
    type: "HuggingfaceBasedExtractor"
    llm: "lmsys/vicuna-13b-v1.5"
  "vicuna-13b-QAExtractor-ollama":
    name: "vicuna:13b-QAExtractor"
    type: "OllamaBasedExtractor"
    llm: "vicuna:13b"
  "gpt-4o-QAExtractor-immediately":
    name: "gpt-4o-QAExtractor-immediately"
    type: "OpenAIBasedExtractor"
    llm: "gpt-4o"
    mode: "immediately"
  "gpt-4o-QAExtractor-batch":
    name: "gpt-4o-QAExtractor-batch"
    type: "OpenAIBasedExtractor"
    llm: "gpt-4o"
    mode: "batch"
  "section_QAExtractor":
    name: "section_QAExtracotr"
    type: "OllamaBasedExtractor"
    llm: "vicuna:13b"
    only_meta:
      level: 
        - "section"
embedding_model:
  "Linq-AI-Research/Linq-Embed-Mistral":
    based_on: "huggingface"
    name: "Linq-AI-Research/Linq-Embed-Mistral"
    cache_dir: "/work/zhengzheng/.hf_cache"
  "ollama-sfr-embedding-mistral":
    based_on: "ollama"
    name: "sammcj/sfr-embedding-mistral:Q4_K_M"
llm:
  "lmsys/vicuna-13b-v1.5":
    based_on: "huggingface"
    model_name: "lmsys/vicuna-13b-v1.5"
    cache_dir: "/work/zhengzheng/.hf_cache"
  "vicuna:13b":
    based_on: "ollama"
    model_name: "vicuna:13b"
  "gpt-4o":
    based_on: "openai"
    model_name: "gpt-4o"
storage:
  "simple":
    embedding_model: "ollama-sfr-embedding-mistral"
    index_generator: VectorStoreIndex
    docstore: SimpleDocumentStore
    vector_store: SimpleVectorStore
    index_store: SimpleIndexStore
    property_graph_store: null
index_pipelines:
  "test":
    - reader: "CustomDocumentReader"
    - break: "-"
    - parser: "CustomHierarchicalNodeParser-hf_vicuna_13b"
    - break: "force"
    - extractor: "gpt-4o-QAExtractor-batch"
    - break: "force"
    - storage: "simple"
  "test-ollama-based":
    - reader: "CustomDocumentReader"
    - parser: "CustomHierarchicalNodeParser-ollama_vicuna_13b"
    - extractor: "section_QAExtractor"
    - storage: "simple" 
  "test-hf":
    - reader: "CustomDocumentReader"
    - parser: "CustomHierarchicalNodeParser-hf_vicuna_13b"
    - extractor: "vicuna-13b-QAExtractor-hf"
    - storage: "simple"
  "test-gpt-4o":
    - reader: "CustomDocumentReader"
    - parser: "CustomHierarchicalNodeParser-ollama_vicuna_13b"
    - break: "-"
    - extractor: "gpt-4o-QAExtractor-immediately"
    - break: "force"
    - storage: "simple"
  "gpt-4o-batch-all":
    - reader: "CustomDocumentReader"
    - break: "-"
    - parser: "CustomHierarchicalNodeParser-hf_vicuna_13b"
    - break: "force"
    - extractor: "gpt-4o-QAExtractor-batch"
    - break: "force"
    - storage: "simple"