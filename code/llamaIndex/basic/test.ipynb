{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "cache_path = '/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/.cache'\n",
    "filenames = [filename for filename in os.listdir(cache_path) if filename.endswith('tei.xml')]\n",
    "\n",
    "\n",
    "def get_full_text(element):\n",
    "    text = element.text or ''\n",
    "    for subelement in element:\n",
    "        text += ET.tostring(subelement, encoding='unicode', method='text')\n",
    "        if subelement.tail:\n",
    "            text += subelement.tail\n",
    "    return text.strip()\n",
    "\n",
    "iter_filenames = (iter(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(cache_path, next(iter_filenames)) \n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {}\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "namespace = {'tei': 'http://www.tei-c.org/ns/1.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title\n",
    "title = root.find('.//tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title', namespaces=namespace)\n",
    "file_dict['title'] = title.text\n",
    "file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors\n",
    "authors = root.findall('.//tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:biblStruct/tei:analytic/tei:author/tei:persName', namespaces=namespace)\n",
    "file_dict['authors'] = []\n",
    "for author in authors:\n",
    "    forename = author.findall('tei:forename', namespaces=namespace)\n",
    "    if len(forename) == 0:\n",
    "        continue\n",
    "    forename = ' '.join(name.text for name in forename)\n",
    "    surname = ' '.join([name.text for name in author.findall('tei:surname', namespaces=namespace)])\n",
    "    author_name = forename + ' ' + surname\n",
    "    file_dict['authors'].append(author_name)\n",
    "file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract\n",
    "abstract = root.find('.//tei:teiHeader/tei:profileDesc/tei:abstract/tei:div/tei:p', namespaces=namespace)\n",
    "print(abstract)\n",
    "if abstract is not None:\n",
    "    file_dict['abstract'] = abstract.text\n",
    "file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body\n",
    "body = root.findall('.//tei:text/tei:body/tei:div', namespaces=namespace)\n",
    "\n",
    "for i, child in enumerate(body):\n",
    "    ps = child.findall('.//tei:p', namespaces=namespace)\n",
    "    if len(ps) == 0:\n",
    "        continue\n",
    "    head = child.find('.//tei:head', namespaces=namespace).text\n",
    "    content = '\\n'.join([get_full_text(p) for p in ps])\n",
    "    file_dict[head] = content\n",
    "file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_document_reader import CustomDocumentReader\n",
    "\n",
    "documents = CustomDocumentReader(\n",
    "    input_dir=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/data\",\n",
    "    cache_dir=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/.cache\",\n",
    "    config_path=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/utils/config.json\",\n",
    "    remove_cache=False\n",
    ")._load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CustomSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "ss1 = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    include_metadata=True,\n",
    "    include_prev_next_rel=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "nodes = ss1.get_nodes_from_documents(documents)\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)\n",
    "docstore.persist(persist_path=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/.cache/test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleFileNodeParser\n",
    "\n",
    "nodes = SimpleFileNodeParser().get_nodes_from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in nodes[0].to_dict().items():\n",
    "    print(f\"key: {k}\\nvalue: {v}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_document_reader import CustomDocumentReader\n",
    "\n",
    "documents = CustomDocumentReader(\n",
    "    input_dir=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/data\",\n",
    "    cache_dir=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/.cache\",\n",
    "    config_path=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/utils/config.json\",\n",
    "    remove_cache=False\n",
    ")._load_data()\n",
    "\n",
    "from utils.custom_parser import CustomHierarchicalNodeParser\n",
    "hnp = CustomHierarchicalNodeParser.from_defaults()\n",
    "hnp._parse_nodes(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test custom document reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_document_reader import CustomDocumentReader\n",
    "\n",
    "documents = CustomDocumentReader(\n",
    "    input_dir=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/data\",\n",
    "    cache_dir=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/.cache\",\n",
    "    config_path=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/utils/config.json\",\n",
    "    remove_cache=False\n",
    ")._load_data()\n",
    "\n",
    "from utils.custom_parser import CustomHierarchicalNodeParser\n",
    "hnp = CustomHierarchicalNodeParser.from_defaults()\n",
    "nodes = hnp.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_extractor import HuggingfaceBasedExtractor, OllamaBasedExtractor, OpenAIBasedExtractor\n",
    "\n",
    "extractor = OllamaBasedExtractor(\n",
    "    model_name='sammcj/sfr-embedding-mistral:Q4_K_M',\n",
    "    only_meta={'level': ['section']}\n",
    ")\n",
    "\n",
    "extractor.extract(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zheng\\miniconda3\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Zheng\\miniconda3\\envs\\llm\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils.get import get_a_store\n",
    "file_path = 'D:\\\\Projects(D)\\\\Fine-Tuned-GPT-2-with-articles-ground-truth\\\\code\\\\llamaIndex\\\\.cache\\\\test-gpt-4o-batch_1_parser_CustomHierarchicalNodeParser-vicuna_13b.json'\n",
    "docstore = get_a_store('SimpleDocumentStore').from_persist_path(persist_path=file_path)\n",
    "nodes = [node for _, node in docstore.docs.items()][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom.custom_extractor import OpenAIBasedQARExtractor\n",
    "from custom.schema import QAR\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "extractor = OpenAIBasedQARExtractor(\n",
    "    model_name='gpt-4o',\n",
    "    cache_dir='D:\\\\Projects(D)\\\\Fine-Tuned-GPT-2-with-articles-ground-truth\\\\code\\\\llamaIndex\\\\.cache',\n",
    "    mode='immediately',\n",
    "    embedding_only=True,\n",
    "    only_meta=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:46<00:00, 11.60s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs = extractor.extract(nodes, 'test', 'test_action', 'D:\\\\Projects(D)\\\\Fine-Tuned-GPT-2-with-articles-ground-truth\\\\code\\\\llamaIndex\\\\.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0].metadata['questions_this_excerpt_can_answer_and_corresponding_answers_and_reasons'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0].metadata['questions_this_excerpt_can_answer_and_corresponding_answers_and_reasons'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_json_str(text: str) -> list:\n",
    "    \"\"\"Extract JSON strings from text.\"\"\"\n",
    "    matches = re.findall(r'\\{.*?\\}', text.strip(), re.MULTILINE | re.IGNORECASE | re.DOTALL)\n",
    "    if not matches:\n",
    "        raise ValueError(f\"Could not extract json strings from output: {text}\")\n",
    "    return matches\n",
    "\n",
    "text = \"\"\"```json\n",
    "[\n",
    "    {\n",
    "        \"Question\": \"What are the main pathological features of Parkinson's disease as described in the document?\",\n",
    "        \"Answer\": \"The main pathological feature of Parkinson's disease is the progressive destruction of dopamine-producing cells in the substantia nigra region of the brain stem.\",\n",
    "        \"Reason\": \"This specific detail about the pathological feature is highlighted in the context and is not general knowledge.\"\n",
    "    },\n",
    "    {\n",
    "        \"Question\": \"How does the document describe the role of neuromelanin in Parkinson's disease?\",\n",
    "        \"Answer\": \"The document suggests that neuromelanin may serve as an indication of catecholamine synthesis in neuronal systems containing dopamine or norepinephrine and may influence neuronal metabolism due to the heavy metals it contains.\",\n",
    "        \"Reason\": \"This insight into neuromelanin's role and its potential impact on neuronal metabolism is unique to the context provided.\"\n",
    "    },\n",
    "    {\n",
    "        \"Question\": \"What evidence does the document provide to support the hypothesis that oxidative stress is involved in Parkinson's disease?\",\n",
    "        \"Answer\": \"The document provides evidence such as increased membrane peroxidation in the substantia nigra, elevated TBA-reactive substance levels, increased 8-hydroxy-2′deoxyguanosine levels, and low phospholipid turnover in the substantia nigra.\",\n",
    "        \"Reason\": \"These specific pieces of evidence are detailed in the context and are not commonly known facts.\"\n",
    "    },\n",
    "    {\n",
    "        \"Question\": \"What are the potential sources of increased oxidative stress in Parkinson's disease according to the document?\",\n",
    "        \"Answer\": \"Potential sources include dopamine metabolism, mitochondrial dysfunction, increased free iron levels, accumulation of AGEs, reduced activity of free radical defense systems, and the deleterious role of glial cells.\",\n",
    "        \"Reason\": \"The document lists these specific sources, providing a comprehensive view that is unique to the context.\"\n",
    "    },\n",
    "    {\n",
    "        \"Question\": \"How does the document describe the involvement of mitochondrial dysfunction in Parkinson's disease?\",\n",
    "        \"Answer\": \"The document describes mitochondrial dysfunction as involving abnormalities of the respiratory chain, particularly a 30-40% decrease in complex I activity in the substantia nigra, which leads to reductions in ATP production and elevated ROS generation.\",\n",
    "        \"Reason\": \"This detailed description of mitochondrial dysfunction and its specific impact on Parkinson's disease is unique to the context provided.\"\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "for k in extract_json_str(text):\n",
    "    print(k)\n",
    "# print(extract_json_str(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.persist(persist_path=\"/home/zhengzheng/scratch0/projects/Fine-Tuned-GPT-2-with-articles-ground-truth/code/llamaIndex/.cache/gpt-4o-batch-all-p_2_parser_CustomHierarchicalNodeParser-hf_vicuna_13b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [node for _, node in docstore.docs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
